{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBFwEMVjHnGI",
        "outputId": "c0353ac1-84c1-489d-fce8-5ca696be1a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/Text Analysis and Sentiment Analysis/Assignment/Assignment Data/Assignment Data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK_io2VlIDqs",
        "outputId": "40b5f8b4-0178-4569-f93b-1c699b4abc86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Text Analysis and Sentiment Analysis/Assignment/Assignment Data/Assignment Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Data_1.txt', 'r') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "print(text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ4JX3mVJdXB",
        "outputId": "25c17028-d7b4-490c-a1d7-6101f422db15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Textual information in the world can be broadly categorized into two main types: facts and opinions. Facts are objective expressions about entities, events, and their properties. Opinions are usually subjective expressions that describe people’s sentiments, appraisals, or feelings toward entities, events, and their properties.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **New Section**\n",
        "Tokenization using split function"
      ],
      "metadata": {
        "id": "4ozTMwMPRHcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform tokenization using python split function\n",
        "# Default splitting without using specifiying string parameter\n",
        "\n",
        "tokens = text_data.split()\n",
        "\n",
        "counter = 0\n",
        "for w in tokens:\n",
        "    counter+=1\n",
        "    print(counter,\".\",w)\n",
        "\n",
        "# Print all the tokens\n",
        "print(tokens)\n",
        "print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJn-DaofJxYj",
        "outputId": "d9d578a3-190d-4ab4-b911-59a39c14f479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 . Textual\n",
            "2 . information\n",
            "3 . in\n",
            "4 . the\n",
            "5 . world\n",
            "6 . can\n",
            "7 . be\n",
            "8 . broadly\n",
            "9 . categorized\n",
            "10 . into\n",
            "11 . two\n",
            "12 . main\n",
            "13 . types:\n",
            "14 . facts\n",
            "15 . and\n",
            "16 . opinions.\n",
            "17 . Facts\n",
            "18 . are\n",
            "19 . objective\n",
            "20 . expressions\n",
            "21 . about\n",
            "22 . entities,\n",
            "23 . events,\n",
            "24 . and\n",
            "25 . their\n",
            "26 . properties.\n",
            "27 . Opinions\n",
            "28 . are\n",
            "29 . usually\n",
            "30 . subjective\n",
            "31 . expressions\n",
            "32 . that\n",
            "33 . describe\n",
            "34 . people’s\n",
            "35 . sentiments,\n",
            "36 . appraisals,\n",
            "37 . or\n",
            "38 . feelings\n",
            "39 . toward\n",
            "40 . entities,\n",
            "41 . events,\n",
            "42 . and\n",
            "43 . their\n",
            "44 . properties.\n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types:', 'facts', 'and', 'opinions.', 'Facts', 'are', 'objective', 'expressions', 'about', 'entities,', 'events,', 'and', 'their', 'properties.', 'Opinions', 'are', 'usually', 'subjective', 'expressions', 'that', 'describe', 'people’s', 'sentiments,', 'appraisals,', 'or', 'feelings', 'toward', 'entities,', 'events,', 'and', 'their', 'properties.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform Splitting specifying specifying comma as string parameter\n",
        "\n",
        "tokens = text_data.split(\",\")\n",
        "counter = 0\n",
        "\n",
        "for w in tokens:\n",
        "    counter+=1\n",
        "    print(counter,\".\",w)\n",
        "\n",
        "# Print all the tokens\n",
        "print(tokens)\n",
        "print()\n",
        "\n",
        "#Specifying the max split parameter before splitting\n",
        "tokens = text_data.split(\",\" , 2)\n",
        "counter = 0\n",
        "for w in tokens:\n",
        "    counter+=1\n",
        "    print(counter,\".\",w)\n",
        "\n",
        "# Print all the tokens\n",
        "print(tokens)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSo42niuOz_3",
        "outputId": "9e4b62d4-4724-422b-9d49-3409c4b46d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 . Textual information in the world can be broadly categorized into two main types: facts and opinions. Facts are objective expressions about entities\n",
            "2 .  events\n",
            "3 .  and their properties. Opinions are usually subjective expressions that describe people’s sentiments\n",
            "4 .  appraisals\n",
            "5 .  or feelings toward entities\n",
            "6 .  events\n",
            "7 .  and their properties.\n",
            "['Textual information in the world can be broadly categorized into two main types: facts and opinions. Facts are objective expressions about entities', ' events', ' and their properties. Opinions are usually subjective expressions that describe people’s sentiments', ' appraisals', ' or feelings toward entities', ' events', ' and their properties.']\n",
            "\n",
            "1 . Textual information in the world can be broadly categorized into two main types: facts and opinions. Facts are objective expressions about entities\n",
            "2 .  events\n",
            "3 .  and their properties. Opinions are usually subjective expressions that describe people’s sentiments, appraisals, or feelings toward entities, events, and their properties.\n",
            "['Textual information in the world can be broadly categorized into two main types: facts and opinions. Facts are objective expressions about entities', ' events', ' and their properties. Opinions are usually subjective expressions that describe people’s sentiments, appraisals, or feelings toward entities, events, and their properties.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section\n",
        "**Tokenization using regular expression**"
      ],
      "metadata": {
        "id": "TabDqgCmRQQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "tokens = re.findall(\"[\\w']+\", text_data)\n",
        "counter = 0\n",
        "for w in tokens:\n",
        "  counter += 1\n",
        "  print(counter, \".\", w)\n",
        "\n",
        "print(tokens)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eyyr-d4RGDg",
        "outputId": "75c356a6-6234-4f11-84a0-1d888da28000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 . Textual\n",
            "2 . information\n",
            "3 . in\n",
            "4 . the\n",
            "5 . world\n",
            "6 . can\n",
            "7 . be\n",
            "8 . broadly\n",
            "9 . categorized\n",
            "10 . into\n",
            "11 . two\n",
            "12 . main\n",
            "13 . types\n",
            "14 . facts\n",
            "15 . and\n",
            "16 . opinions\n",
            "17 . Facts\n",
            "18 . are\n",
            "19 . objective\n",
            "20 . expressions\n",
            "21 . about\n",
            "22 . entities\n",
            "23 . events\n",
            "24 . and\n",
            "25 . their\n",
            "26 . properties\n",
            "27 . Opinions\n",
            "28 . are\n",
            "29 . usually\n",
            "30 . subjective\n",
            "31 . expressions\n",
            "32 . that\n",
            "33 . describe\n",
            "34 . people\n",
            "35 . s\n",
            "36 . sentiments\n",
            "37 . appraisals\n",
            "38 . or\n",
            "39 . feelings\n",
            "40 . toward\n",
            "41 . entities\n",
            "42 . events\n",
            "43 . and\n",
            "44 . their\n",
            "45 . properties\n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types', 'facts', 'and', 'opinions', 'Facts', 'are', 'objective', 'expressions', 'about', 'entities', 'events', 'and', 'their', 'properties', 'Opinions', 'are', 'usually', 'subjective', 'expressions', 'that', 'describe', 'people', 's', 'sentiments', 'appraisals', 'or', 'feelings', 'toward', 'entities', 'events', 'and', 'their', 'properties']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section\n",
        "**Tokenization using NLTK Packages**"
      ],
      "metadata": {
        "id": "9jW746NcVh6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "Tokens = word_tokenize(text_data)\n",
        "\n",
        "print(\"There are \", len(Tokens), \"tokens in this text\\n\")\n",
        "\n",
        "counter = 0\n",
        "for w in Tokens:\n",
        "    counter+=1\n",
        "    print(counter,\".\",w)\n",
        "\n",
        "\n",
        "# To print all the tokens\n",
        "print(Tokens)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb1kZquiKE2Q",
        "outputId": "ee4b1812-1159-46fd-fc25-8d8a772c78a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are  56 tokens in this text\n",
            "\n",
            "1 . Textual\n",
            "2 . information\n",
            "3 . in\n",
            "4 . the\n",
            "5 . world\n",
            "6 . can\n",
            "7 . be\n",
            "8 . broadly\n",
            "9 . categorized\n",
            "10 . into\n",
            "11 . two\n",
            "12 . main\n",
            "13 . types\n",
            "14 . :\n",
            "15 . facts\n",
            "16 . and\n",
            "17 . opinions\n",
            "18 . .\n",
            "19 . Facts\n",
            "20 . are\n",
            "21 . objective\n",
            "22 . expressions\n",
            "23 . about\n",
            "24 . entities\n",
            "25 . ,\n",
            "26 . events\n",
            "27 . ,\n",
            "28 . and\n",
            "29 . their\n",
            "30 . properties\n",
            "31 . .\n",
            "32 . Opinions\n",
            "33 . are\n",
            "34 . usually\n",
            "35 . subjective\n",
            "36 . expressions\n",
            "37 . that\n",
            "38 . describe\n",
            "39 . people\n",
            "40 . ’\n",
            "41 . s\n",
            "42 . sentiments\n",
            "43 . ,\n",
            "44 . appraisals\n",
            "45 . ,\n",
            "46 . or\n",
            "47 . feelings\n",
            "48 . toward\n",
            "49 . entities\n",
            "50 . ,\n",
            "51 . events\n",
            "52 . ,\n",
            "53 . and\n",
            "54 . their\n",
            "55 . properties\n",
            "56 . .\n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types', ':', 'facts', 'and', 'opinions', '.', 'Facts', 'are', 'objective', 'expressions', 'about', 'entities', ',', 'events', ',', 'and', 'their', 'properties', '.', 'Opinions', 'are', 'usually', 'subjective', 'expressions', 'that', 'describe', 'people', '’', 's', 'sentiments', ',', 'appraisals', ',', 'or', 'feelings', 'toward', 'entities', ',', 'events', ',', 'and', 'their', 'properties', '.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization using text blob**"
      ],
      "metadata": {
        "id": "wPEPsvgoYqKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "tokens = TextBlob(text_data).words\n",
        "\n",
        "count = 0\n",
        "for w in tokens:\n",
        "  count+=1\n",
        "  print(count, \".\", w)\n",
        "\n",
        "print(tokens)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mtD3_DaKw3L",
        "outputId": "479b7523-76b2-4bc6-ee54-b6690e5d0405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 . Textual\n",
            "2 . information\n",
            "3 . in\n",
            "4 . the\n",
            "5 . world\n",
            "6 . can\n",
            "7 . be\n",
            "8 . broadly\n",
            "9 . categorized\n",
            "10 . into\n",
            "11 . two\n",
            "12 . main\n",
            "13 . types\n",
            "14 . facts\n",
            "15 . and\n",
            "16 . opinions\n",
            "17 . Facts\n",
            "18 . are\n",
            "19 . objective\n",
            "20 . expressions\n",
            "21 . about\n",
            "22 . entities\n",
            "23 . events\n",
            "24 . and\n",
            "25 . their\n",
            "26 . properties\n",
            "27 . Opinions\n",
            "28 . are\n",
            "29 . usually\n",
            "30 . subjective\n",
            "31 . expressions\n",
            "32 . that\n",
            "33 . describe\n",
            "34 . people\n",
            "35 . ’\n",
            "36 . s\n",
            "37 . sentiments\n",
            "38 . appraisals\n",
            "39 . or\n",
            "40 . feelings\n",
            "41 . toward\n",
            "42 . entities\n",
            "43 . events\n",
            "44 . and\n",
            "45 . their\n",
            "46 . properties\n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types', 'facts', 'and', 'opinions', 'Facts', 'are', 'objective', 'expressions', 'about', 'entities', 'events', 'and', 'their', 'properties', 'Opinions', 'are', 'usually', 'subjective', 'expressions', 'that', 'describe', 'people', '’', 's', 'sentiments', 'appraisals', 'or', 'feelings', 'toward', 'entities', 'events', 'and', 'their', 'properties']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(text_data)\n",
        "count = 0\n",
        "for token in doc:\n",
        "  count += 1\n",
        "  print(count, token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV931SeSYnHi",
        "outputId": "4358e9a8-653e-435e-bde6-b2bb0d84dee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Textual\n",
            "2 information\n",
            "3 in\n",
            "4 the\n",
            "5 world\n",
            "6 can\n",
            "7 be\n",
            "8 broadly\n",
            "9 categorized\n",
            "10 into\n",
            "11 two\n",
            "12 main\n",
            "13 types\n",
            "14 :\n",
            "15 facts\n",
            "16 and\n",
            "17 opinions\n",
            "18 .\n",
            "19 Facts\n",
            "20 are\n",
            "21 objective\n",
            "22 expressions\n",
            "23 about\n",
            "24 entities\n",
            "25 ,\n",
            "26 events\n",
            "27 ,\n",
            "28 and\n",
            "29 their\n",
            "30 properties\n",
            "31 .\n",
            "32 Opinions\n",
            "33 are\n",
            "34 usually\n",
            "35 subjective\n",
            "36 expressions\n",
            "37 that\n",
            "38 describe\n",
            "39 people\n",
            "40 ’s\n",
            "41 sentiments\n",
            "42 ,\n",
            "43 appraisals\n",
            "44 ,\n",
            "45 or\n",
            "46 feelings\n",
            "47 toward\n",
            "48 entities\n",
            "49 ,\n",
            "50 events\n",
            "51 ,\n",
            "52 and\n",
            "53 their\n",
            "54 properties\n",
            "55 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Textual information in the world can be broadly categorized into two main types: facts and opinions.\"\n",
        "\n",
        "wordtokens = re.findall(\"[\\w']+\", text)\n",
        "print(\"Tokenisation using regular expression findall function ~~~~~~~~~~~~~~~ \")\n",
        "print(wordtokens)\n",
        "\n",
        "wordtokens = text.split(' ')\n",
        "print(\"Tokenisation using python split function ~~~~~~~~~~~~~~~ \")\n",
        "print(wordtokens)\n",
        "\n",
        "print(\"\\nTokenisation using nltk word tokenise function ~~~~~~~~~~~~~~~ \")\n",
        "print(word_tokenize(text))\n",
        "\n",
        "print(\"\\nTokenisation using textblob tokenise function ~~~~~~~~~~~~~~~ \")\n",
        "print(TextBlob(text).words)\n",
        "\n",
        "print(\"\\nTokenisation using spacy tokenise function ~~~~~~~~~~~~~~~ \")\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6llbzWGZnKI",
        "outputId": "b6f0067e-7df6-4848-b305-a3f59b4b9d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenisation using regular expression findall function ~~~~~~~~~~~~~~~ \n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types', 'facts', 'and', 'opinions']\n",
            "Tokenisation using python split function ~~~~~~~~~~~~~~~ \n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types:', 'facts', 'and', 'opinions.']\n",
            "\n",
            "Tokenisation using nltk word tokenise function ~~~~~~~~~~~~~~~ \n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types', ':', 'facts', 'and', 'opinions', '.']\n",
            "\n",
            "Tokenisation using textblob tokenise function ~~~~~~~~~~~~~~~ \n",
            "['Textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types', 'facts', 'and', 'opinions']\n",
            "\n",
            "Tokenisation using spacy tokenise function ~~~~~~~~~~~~~~~ \n",
            "Textual\n",
            "information\n",
            "in\n",
            "the\n",
            "world\n",
            "can\n",
            "be\n",
            "broadly\n",
            "categorized\n",
            "into\n",
            "two\n",
            "main\n",
            "types\n",
            ":\n",
            "facts\n",
            "and\n",
            "opinions\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text_lower = text_data.lower()\n",
        "wordtokens = nltk.tokenize.word_tokenize(text_lower)\n",
        "print(wordtokens)\n",
        "\n",
        "print(\"\\nTotal number of words in this text corpus is\", len(wordtokens))\n",
        "\n",
        "stopTokens = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
        "filteredTokens = []\n",
        "\n",
        "stopWordsFound = []\n",
        "\n",
        "for w in wordtokens:\n",
        "    if w in stopTokens:\n",
        "        stopWordsFound.append(w)\n",
        "    else:\n",
        "        filteredTokens.append(w)\n",
        "\n",
        "print(\"There are\", len(filteredTokens), \"words in this text corpus after removing stop words and punctuations \\n\")\n",
        "print(filteredTokens)\n",
        "print(\"There are\", len(stopWordsFound), \"stop words and punctuations in this text corpus:\\n\")\n",
        "print(stopWordsFound)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHZGM0ZUa170",
        "outputId": "be051fbf-bace-4df1-ed74-2cd9fd17f57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['textual', 'information', 'in', 'the', 'world', 'can', 'be', 'broadly', 'categorized', 'into', 'two', 'main', 'types', ':', 'facts', 'and', 'opinions', '.', 'facts', 'are', 'objective', 'expressions', 'about', 'entities', ',', 'events', ',', 'and', 'their', 'properties', '.', 'opinions', 'are', 'usually', 'subjective', 'expressions', 'that', 'describe', 'people', '’', 's', 'sentiments', ',', 'appraisals', ',', 'or', 'feelings', 'toward', 'entities', ',', 'events', ',', 'and', 'their', 'properties', '.']\n",
            "\n",
            "Total number of words in this text corpus is 56\n",
            "There are 30 words in this text corpus after removing stop words and punctuations \n",
            "\n",
            "['textual', 'information', 'world', 'broadly', 'categorized', 'two', 'main', 'types', 'facts', 'opinions', 'facts', 'objective', 'expressions', 'entities', 'events', 'properties', 'opinions', 'usually', 'subjective', 'expressions', 'describe', 'people', '’', 'sentiments', 'appraisals', 'feelings', 'toward', 'entities', 'events', 'properties']\n",
            "There are 26 stop words and punctuations in this text corpus:\n",
            "\n",
            "['in', 'the', 'can', 'be', 'into', ':', 'and', '.', 'are', 'about', ',', ',', 'and', 'their', '.', 'are', 'that', 's', ',', ',', 'or', ',', ',', 'and', 'their', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9KXvyAp4c6OR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}