{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Refer to code implementations of Language Modelling: https://colab.research.google.com/drive/1ISx9SAXQpLTdlaO4AZ8Kzi3BDcwq9Dty#scrollTo=ccQePt1h1tW6"
      ],
      "metadata": {
        "id": "r4F4vV4F-I8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t2xipd54BUUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d265faeb-98fa-4001-8eb8-e7ae86206dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL4___nsioZ8",
        "outputId": "6c094e04-1c45-42e7-8b4a-a94a244b4875"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/TXSA_Assignment/Assignment Data/Data_3.txt\"\n",
        "file = open(data_path, \"r\")\n",
        "text = \"\"\n",
        "for line in file.readlines():\n",
        "    print(line, end=\"\")\n",
        "    text += line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDkJpQtGBtsk",
        "outputId": "8fd41b12-a58b-4a60-c7bc-ae47b76e0116"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Corpus\n",
            "~~~~~~~~~~~~~\n",
            "<s> He read a book </s>\n",
            "<s> I read a different book </s>\n",
            "<s> He read a book by Danielle </s>\n",
            "\n",
            "Calculate sentence probability for the following sentence\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "<s> I read a book by Danielle </s>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text_corpus = re.findall(\"<s>.+</s>\", text)\n",
        "text_corpus = [sentence.split() for sentence in text_corpus]\n",
        "test_sentence = \" \".join(text_corpus.pop())\n",
        "print(text_corpus)\n",
        "print(test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAFGFfFaX8EZ",
        "outputId": "805deacd-b20a-4739-9b16-798842c4da40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['<s>', 'He', 'read', 'a', 'book', '</s>'], ['<s>', 'I', 'read', 'a', 'different', 'book', '</s>'], ['<s>', 'He', 'read', 'a', 'book', 'by', 'Danielle', '</s>']]\n",
            "<s> I read a book by Danielle </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import flatten\n",
        "text_corpus = list(flatten(text_corpus))\n",
        "text_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pusQiY82XiM6",
        "outputId": "a27fd9fd-9ab5-4cd4-ba12-7c3e6a761374"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'He',\n",
              " 'read',\n",
              " 'a',\n",
              " 'book',\n",
              " '</s>',\n",
              " '<s>',\n",
              " 'I',\n",
              " 'read',\n",
              " 'a',\n",
              " 'different',\n",
              " 'book',\n",
              " '</s>',\n",
              " '<s>',\n",
              " 'He',\n",
              " 'read',\n",
              " 'a',\n",
              " 'book',\n",
              " 'by',\n",
              " 'Danielle',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute sentence probabilities manually"
      ],
      "metadata": {
        "id": "ymb03bbIo4ja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using unsmoothed bigram model: <br>\n",
        "$P(\\text{<s> I read a book by Danielle </s>}) $ <br>\n",
        "$= P(I|<s>) \\cdot P(read|I) \\cdot P(a|read) \\cdot P(book|a) \\cdot P(by|book) \\cdot P(Danielle|by) \\cdot P(</s>|Danielle)$ <br>\n",
        "$ = \\frac{1}{3} \\cdot \\frac{1}{1} \\cdot \\frac{3}{3} \\cdot \\frac{2}{3} \\cdot \\frac{1}{3} \\cdot \\frac{1}{1} \\cdot \\frac{1}{1} = 0.07407407407$"
      ],
      "metadata": {
        "id": "YlARYjyXpGQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using smoothed bigram model: <br>\n",
        "$P(\\text{<s> I read a book by Danielle </s>}) $ <br>\n",
        "$= P(I|<s>) \\cdot P(read|I) \\cdot P(a|read) \\cdot P(book|a) \\cdot P(by|book) \\cdot P(Danielle|by) \\cdot P(</s>|Danielle)$ <br>\n",
        "$ = \\frac{1 + 1}{3 + 10 + 1} \\cdot \\frac{1 + 1}{1 + 10 + 1} \\cdot \\frac{3 + 1}{3 + 10 + 1} \\cdot \\frac{2 +1}{3 + 10 + 1} \\cdot \\frac{1+1}{3 + 10 + 1} \\cdot \\frac{1+1}{1+ 10 + 1} \\cdot \\frac{1+1}{1+ 10 + 1} = 0.00000578462677588$"
      ],
      "metadata": {
        "id": "JXpk65UbpgvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute sentence probabilities by using Python codes"
      ],
      "metadata": {
        "id": "uE_LcFMWo84S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabs = set(text_corpus)\n",
        "print(vocabs)\n",
        "print(len(vocabs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHExtdkwsQ6L",
        "outputId": "1514e275-5244-4a72-e165-869f2259fd4b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I', '<s>', 'He', 'a', 'by', 'book', 'Danielle', 'different', 'read', '</s>'}\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sentence_probability_unsmoothed_bigram(sentence, vocabs, text_corpus):\n",
        "    tokens = sentence.split()\n",
        "    bigram_counts = {}\n",
        "    # Sliding through corpus to get bigram counts\n",
        "    for i in range(len(text_corpus) - 1):\n",
        "        # Getting bigram at each slide\n",
        "        bigram = (text_corpus[i], text_corpus[i+1])\n",
        "        # Keeping track of the bigram counts\n",
        "        if bigram in bigram_counts.keys():\n",
        "            bigram_counts[bigram] += 1\n",
        "        else:\n",
        "            bigram_counts[bigram] = 1\n",
        "\n",
        "    vocab_counts = {}\n",
        "    # Sliding through vocabs to get vocab counts\n",
        "    for vocab in vocabs:\n",
        "        for word in text_corpus:\n",
        "            if word == vocab:\n",
        "                if vocab in vocab_counts.keys():\n",
        "                  vocab_counts[vocab] += 1\n",
        "                else:\n",
        "                  vocab_counts[vocab] = 1\n",
        "    sentence_prob = 1\n",
        "    # Sliding through the `tokens` to get bigrams\n",
        "    for i in range(len(tokens) - 1):\n",
        "        # Getting bigram at each slide\n",
        "        bigram = (tokens[i], tokens[i+1])\n",
        "        sentence_prob *= bigram_counts.get(bigram, 0)/ (vocab_counts.get(tokens[i]))\n",
        "    return sentence_prob"
      ],
      "metadata": {
        "id": "syGw5AkTwOMj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_sentence_probability_unsmoothed_bigram(test_sentence, vocabs, text_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHG_J2L7Hd7u",
        "outputId": "5bf05da2-f263-4a50-8eef-b66f6df1fca9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07407407407407407"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_sentence_probability_smoothed_bigram(sentence, vocabs, text_corpus):\n",
        "    tokens = sentence.split()\n",
        "    bigram_counts = {}\n",
        "    # Sliding through corpus to get bigram counts\n",
        "    for i in range(len(text_corpus) - 1):\n",
        "        # Getting bigram at each slide\n",
        "        bigram = (text_corpus[i], text_corpus[i+1])\n",
        "        # Keeping track of the bigram counts\n",
        "        if bigram in bigram_counts.keys():\n",
        "            bigram_counts[bigram] += 1\n",
        "        else:\n",
        "            bigram_counts[bigram] = 1\n",
        "\n",
        "    vocab_counts = {}\n",
        "    # Sliding through vocabs to get vocab counts\n",
        "    for vocab in vocabs:\n",
        "        for word in text_corpus:\n",
        "            if word == vocab:\n",
        "                if vocab in vocab_counts.keys():\n",
        "                  vocab_counts[vocab] += 1\n",
        "                else:\n",
        "                  vocab_counts[vocab] = 1\n",
        "    sentence_prob = 1\n",
        "    # Sliding through the `tokens` to get bigrams\n",
        "    for i in range(len(tokens) - 1):\n",
        "        # Getting bigram at each slide\n",
        "        bigram = (tokens[i], tokens[i+1])\n",
        "        sentence_prob *= (bigram_counts.get(bigram, 0) + 1)/(vocab_counts.get(tokens[i]) + len(vocabs) + 1)\n",
        "    return sentence_prob"
      ],
      "metadata": {
        "id": "hUtATPp6H5hQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_sentence_probability_smoothed_bigram(test_sentence, vocabs, text_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO2F3ZNALyVn",
        "outputId": "a45130bf-e273-48ae-c83d-7a215d7e2bd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.784626775880419e-06"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}